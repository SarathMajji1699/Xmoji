{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Sequential #for initializing\n",
    "from tensorflow.keras.layers import Dense  #adding layers\n",
    "from tensorflow.keras.layers import Conv2D  #adding convolution layer\n",
    "from tensorflow.keras.layers import MaxPooling2D  #max pooling\n",
    "from tensorflow.keras.layers import Flatten,Dropout,Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "val_dir = 'data/test'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)\n",
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "448/448 [==============================] - 310s 692ms/step - loss: 1.7975 - accuracy: 0.2635 - val_loss: 1.6993 - val_accuracy: 0.3495\n",
      "Epoch 2/50\n",
      "448/448 [==============================] - 298s 664ms/step - loss: 1.6255 - accuracy: 0.3689 - val_loss: 1.5411 - val_accuracy: 0.4169\n",
      "Epoch 3/50\n",
      "448/448 [==============================] - 295s 658ms/step - loss: 1.5255 - accuracy: 0.4145 - val_loss: 1.4670 - val_accuracy: 0.4406\n",
      "Epoch 4/50\n",
      "448/448 [==============================] - 289s 644ms/step - loss: 1.4539 - accuracy: 0.4449 - val_loss: 1.4013 - val_accuracy: 0.4625\n",
      "Epoch 5/50\n",
      "448/448 [==============================] - 292s 653ms/step - loss: 1.3938 - accuracy: 0.4680 - val_loss: 1.3654 - val_accuracy: 0.4796\n",
      "Epoch 6/50\n",
      "448/448 [==============================] - 259s 579ms/step - loss: 1.3436 - accuracy: 0.4905 - val_loss: 1.3100 - val_accuracy: 0.5025\n",
      "Epoch 7/50\n",
      "448/448 [==============================] - 270s 602ms/step - loss: 1.2987 - accuracy: 0.5087 - val_loss: 1.2828 - val_accuracy: 0.5084\n",
      "Epoch 8/50\n",
      "448/448 [==============================] - 347s 774ms/step - loss: 1.2596 - accuracy: 0.5241 - val_loss: 1.2526 - val_accuracy: 0.5258\n",
      "Epoch 9/50\n",
      "448/448 [==============================] - 329s 734ms/step - loss: 1.2254 - accuracy: 0.5394 - val_loss: 1.2283 - val_accuracy: 0.5301\n",
      "Epoch 10/50\n",
      "448/448 [==============================] - 358s 800ms/step - loss: 1.1956 - accuracy: 0.5491 - val_loss: 1.1959 - val_accuracy: 0.5481\n",
      "Epoch 11/50\n",
      "448/448 [==============================] - 326s 728ms/step - loss: 1.1667 - accuracy: 0.5618 - val_loss: 1.1873 - val_accuracy: 0.5481\n",
      "Epoch 12/50\n",
      "448/448 [==============================] - 351s 784ms/step - loss: 1.1432 - accuracy: 0.5700 - val_loss: 1.1830 - val_accuracy: 0.5499\n",
      "Epoch 13/50\n",
      "448/448 [==============================] - 328s 731ms/step - loss: 1.1210 - accuracy: 0.5814 - val_loss: 1.1544 - val_accuracy: 0.5632\n",
      "Epoch 14/50\n",
      "448/448 [==============================] - 360s 803ms/step - loss: 1.0840 - accuracy: 0.5940 - val_loss: 1.1384 - val_accuracy: 0.5678\n",
      "Epoch 15/50\n",
      "448/448 [==============================] - 343s 766ms/step - loss: 1.0685 - accuracy: 0.6027 - val_loss: 1.1339 - val_accuracy: 0.5725\n",
      "Epoch 16/50\n",
      "448/448 [==============================] - 292s 651ms/step - loss: 1.0419 - accuracy: 0.6126 - val_loss: 1.1202 - val_accuracy: 0.5724\n",
      "Epoch 17/50\n",
      "448/448 [==============================] - 267s 595ms/step - loss: 1.0225 - accuracy: 0.6198 - val_loss: 1.1052 - val_accuracy: 0.5773\n",
      "Epoch 18/50\n",
      "448/448 [==============================] - 257s 574ms/step - loss: 0.9979 - accuracy: 0.6305 - val_loss: 1.1012 - val_accuracy: 0.5812\n",
      "Epoch 19/50\n",
      "448/448 [==============================] - 244s 544ms/step - loss: 0.9739 - accuracy: 0.6384 - val_loss: 1.1080 - val_accuracy: 0.5844\n",
      "Epoch 20/50\n",
      "448/448 [==============================] - 239s 533ms/step - loss: 0.9526 - accuracy: 0.6496 - val_loss: 1.0848 - val_accuracy: 0.5928\n",
      "Epoch 21/50\n",
      "448/448 [==============================] - 241s 539ms/step - loss: 0.9304 - accuracy: 0.6566 - val_loss: 1.0795 - val_accuracy: 0.5921\n",
      "Epoch 22/50\n",
      "448/448 [==============================] - 248s 553ms/step - loss: 0.9069 - accuracy: 0.6655 - val_loss: 1.0899 - val_accuracy: 0.5957\n",
      "Epoch 23/50\n",
      "448/448 [==============================] - 252s 563ms/step - loss: 0.8824 - accuracy: 0.6743 - val_loss: 1.0873 - val_accuracy: 0.6039\n",
      "Epoch 24/50\n",
      "448/448 [==============================] - 244s 545ms/step - loss: 0.8573 - accuracy: 0.6867 - val_loss: 1.0739 - val_accuracy: 0.6021\n",
      "Epoch 25/50\n",
      "448/448 [==============================] - 240s 535ms/step - loss: 0.8449 - accuracy: 0.6883 - val_loss: 1.0654 - val_accuracy: 0.6083\n",
      "Epoch 26/50\n",
      "448/448 [==============================] - 240s 535ms/step - loss: 0.8194 - accuracy: 0.6991 - val_loss: 1.0834 - val_accuracy: 0.6048\n",
      "Epoch 27/50\n",
      "448/448 [==============================] - 239s 533ms/step - loss: 0.7953 - accuracy: 0.7092 - val_loss: 1.0786 - val_accuracy: 0.6056\n",
      "Epoch 28/50\n",
      "448/448 [==============================] - 241s 538ms/step - loss: 0.7721 - accuracy: 0.7206 - val_loss: 1.0701 - val_accuracy: 0.6070\n",
      "Epoch 29/50\n",
      "448/448 [==============================] - 238s 532ms/step - loss: 0.7510 - accuracy: 0.7249 - val_loss: 1.0776 - val_accuracy: 0.6057\n",
      "Epoch 30/50\n",
      "448/448 [==============================] - 240s 535ms/step - loss: 0.7286 - accuracy: 0.7359 - val_loss: 1.0792 - val_accuracy: 0.6083\n",
      "Epoch 31/50\n",
      "448/448 [==============================] - 248s 554ms/step - loss: 0.7105 - accuracy: 0.7393 - val_loss: 1.0776 - val_accuracy: 0.6145\n",
      "Epoch 32/50\n",
      "448/448 [==============================] - 239s 534ms/step - loss: 0.6765 - accuracy: 0.7542 - val_loss: 1.0776 - val_accuracy: 0.6164\n",
      "Epoch 33/50\n",
      "448/448 [==============================] - 240s 537ms/step - loss: 0.6692 - accuracy: 0.7563 - val_loss: 1.0842 - val_accuracy: 0.6091\n",
      "Epoch 34/50\n",
      "448/448 [==============================] - 238s 532ms/step - loss: 0.6391 - accuracy: 0.7637 - val_loss: 1.0802 - val_accuracy: 0.6150\n",
      "Epoch 35/50\n",
      "448/448 [==============================] - 239s 534ms/step - loss: 0.6245 - accuracy: 0.7733 - val_loss: 1.0895 - val_accuracy: 0.6194\n",
      "Epoch 36/50\n",
      "448/448 [==============================] - 239s 534ms/step - loss: 0.6009 - accuracy: 0.7805 - val_loss: 1.0874 - val_accuracy: 0.6265\n",
      "Epoch 37/50\n",
      "448/448 [==============================] - 2540s 6s/step - loss: 0.5779 - accuracy: 0.7893 - val_loss: 1.1086 - val_accuracy: 0.6256\n",
      "Epoch 38/50\n",
      "448/448 [==============================] - 225s 503ms/step - loss: 0.5635 - accuracy: 0.7941 - val_loss: 1.1075 - val_accuracy: 0.6164\n",
      "Epoch 39/50\n",
      "448/448 [==============================] - 222s 496ms/step - loss: 0.5434 - accuracy: 0.8019 - val_loss: 1.1255 - val_accuracy: 0.6217\n",
      "Epoch 40/50\n",
      "448/448 [==============================] - 222s 495ms/step - loss: 0.5311 - accuracy: 0.8087 - val_loss: 1.1293 - val_accuracy: 0.6236\n",
      "Epoch 41/50\n",
      "448/448 [==============================] - 223s 497ms/step - loss: 0.5098 - accuracy: 0.8161 - val_loss: 1.1086 - val_accuracy: 0.6228\n",
      "Epoch 42/50\n",
      "448/448 [==============================] - 221s 493ms/step - loss: 0.4995 - accuracy: 0.8184 - val_loss: 1.1317 - val_accuracy: 0.6239\n",
      "Epoch 43/50\n",
      "448/448 [==============================] - 223s 497ms/step - loss: 0.4757 - accuracy: 0.8294 - val_loss: 1.1436 - val_accuracy: 0.6251\n",
      "Epoch 44/50\n",
      "448/448 [==============================] - 227s 506ms/step - loss: 0.4648 - accuracy: 0.8328 - val_loss: 1.1513 - val_accuracy: 0.6225\n",
      "Epoch 45/50\n",
      "448/448 [==============================] - 222s 495ms/step - loss: 0.4421 - accuracy: 0.8426 - val_loss: 1.1583 - val_accuracy: 0.6229\n",
      "Epoch 46/50\n",
      "448/448 [==============================] - 222s 496ms/step - loss: 0.4319 - accuracy: 0.8441 - val_loss: 1.1594 - val_accuracy: 0.6256\n",
      "Epoch 47/50\n",
      "448/448 [==============================] - 230s 513ms/step - loss: 0.4187 - accuracy: 0.8473 - val_loss: 1.1695 - val_accuracy: 0.6237\n",
      "Epoch 48/50\n",
      "448/448 [==============================] - 223s 497ms/step - loss: 0.4049 - accuracy: 0.8542 - val_loss: 1.1871 - val_accuracy: 0.6281\n",
      "Epoch 49/50\n",
      "448/448 [==============================] - 237s 528ms/step - loss: 0.3917 - accuracy: 0.8619 - val_loss: 1.1845 - val_accuracy: 0.6270\n",
      "Epoch 50/50\n",
      "448/448 [==============================] - 230s 513ms/step - loss: 0.3785 - accuracy: 0.8641 - val_loss: 1.2107 - val_accuracy: 0.6254\n"
     ]
    }
   ],
   "source": [
    "emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
    "emotion_model_info = emotion_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64)\n",
    "emotion_model.save_weights('emotion_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
